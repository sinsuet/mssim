import os
import json
from flask import Flask, request, jsonify
from pydantic import ValidationError
import dashscope
from dashscope.api_entities.dashscope_response import Role
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ API Key
load_dotenv()

# å¯¼å…¥åè®®å®šä¹‰
from protocol import ContextPack, SearchSpec

app = Flask(__name__)

# é…ç½® Qwen æ¨¡å‹
MODEL_NAME = 'qwen-plus' 

# æ£€æŸ¥ API Key
if not os.environ.get("DASHSCOPE_API_KEY") and not dashscope.api_key:
    print("âš ï¸ Warning: DASHSCOPE_API_KEY not found. Please set it in .env or environment variables.")

def call_qwen_brain(context_md: str) -> str:
    """
    å°è£… DashScope API è°ƒç”¨é€»è¾‘
    """
    # --- [å…³é”®ä¿®æ”¹] æ³¨å…¥å¼º JSON ç»“æ„çš„ System Prompt ---
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªå«æ˜Ÿçƒ­æ§ç³»ç»Ÿçš„AIè®¾è®¡ä¸“å®¶ (DV1.2 Brain)ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è¾“å…¥çš„ç‰©ç†è®¾è®¡ç°çŠ¶ (ContextPack)ï¼Œè¾“å‡ºç¬¦åˆä¸¥æ ¼ Schema å®šä¹‰çš„ä¼˜åŒ–æŒ‡ä»¤ (SearchSpec)ã€‚

    ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘
    ä½ å¿…é¡»è¾“å‡ºå¦‚ä¸‹ç»“æ„çš„çº¯ JSON (ä¸è¦ä½¿ç”¨ Markdown ä»£ç å—):
    {
        "plan_id": "PLAN_YYYYMMDD_001",
        "reasoning_summary": "è¿™é‡Œå†™å®è§‚ç­–ç•¥ï¼Œè§£é‡Šä¸ºä»€ä¹ˆè¦é€‰è¿™ä¸ªæ–¹å‘ï¼ˆä¾‹å¦‚ï¼šå› ä¸º+Xæ–¹å‘æœ‰å¹²æ¶‰ï¼Œæ‰€ä»¥å°è¯•å¾€-Yæ–¹å‘ç§»åŠ¨ï¼‰",
        "actions": [
            {
                "op_id": "MOVE",
                "target_component": "ç»„ä»¶åç§°",
                "search_axis": "Y", 
                "bounds": [-50.0, 0.0],
                "unit": "mm",
                "conflicts": ["å…³è”çš„è¿è§„ID"],
                "hints": ["Try moving away from heat source"]
            }
        ]
    }

    ã€ç‰©ç†è§„åˆ™çº¦æŸã€‘
    1. search_axis åªèƒ½æ˜¯ "X", "Y", æˆ– "Z" ä¸­çš„ä¸€ä¸ªã€‚
    2. bounds å¿…é¡»æ˜¯ä¸¤ä¸ªæ•°å­—çš„åˆ—è¡¨ [min, max]ï¼Œä»£è¡¨ç›¸å¯¹äºå½“å‰ä½ç½®çš„æœç´¢èŒƒå›´ã€‚
    3. op_id åªèƒ½æ˜¯: "MOVE", "SWAP", "ADD_SURFACE"ã€‚
    4. å¦‚æœæ˜¯ MOVE æ“ä½œï¼Œè¯·åªé€‰æ‹©ä¸€ä¸ªæœ€æœ‰å¯èƒ½è§£å†³é—®é¢˜çš„è½´å‘è¿›è¡Œæœç´¢ï¼Œä¸è¦åŒæ—¶ç»™å‡ºä¸‰ä¸ªè½´ã€‚
    """

    messages = [
        {'role': Role.SYSTEM, 'content': system_prompt},
        {'role': Role.USER, 'content': f"å½“å‰è®¾è®¡çŠ¶æ€å¦‚ä¸‹ï¼š\n{context_md}"}
    ]

    try:
        response = dashscope.Generation.call(
            model=MODEL_NAME,
            messages=messages,
            result_format='message',
            temperature=0.5, # é™ä½æ¸©åº¦ï¼Œè®©ç»“æ„æ›´ç¨³å®š
        )

        if response.status_code == 200:
            return response.output.choices[0].message.content
        else:
            raise Exception(f"Qwen API Error: {response.code} - {response.message}")

    except Exception as e:
        raise Exception(f"Model Inference Failed: {str(e)}")

@app.route('/optimize', methods=['POST'])
def optimize_design():
    try:
        # Step 1: æ¥æ”¶è¾“å…¥
        input_data = request.json
        context = ContextPack(**input_data)
        
        # Step 2: è½¬æ¢ä¸º Prompt
        context_md = context.to_markdown_prompt()
        print(f"--- [Log] Sending to {MODEL_NAME} ---\n{context_md[:100]}...")

        # Step 3: è°ƒç”¨ LLM
        llm_raw_output = call_qwen_brain(context_md)
        print(f"--- [Log] Qwen Response (Raw) ---\n{llm_raw_output}")

        # Step 4: æ¸…æ´—æ•°æ® (å¤„ç†å¯èƒ½å­˜åœ¨çš„ Markdown æ ‡è®°)
        clean_json_str = llm_raw_output.strip()
        if clean_json_str.startswith("```json"):
            clean_json_str = clean_json_str[7:]
        if clean_json_str.endswith("```"):
            clean_json_str = clean_json_str[:-3]
        
        spec_dict = json.loads(clean_json_str.strip())

        # Step 5: Pydantic å¼ºæ ¡éªŒ
        validated_spec = SearchSpec(**spec_dict)

        # Step 6: è¿”å›ç»“æœ
        return jsonify(validated_spec.model_dump()), 200

    except ValidationError as ve:
        print(f"âŒ Protocol Violation: {ve}")
        # è¿”å›è¯¦ç»†çš„ Pydantic é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
        return jsonify({"error": "Protocol Violation", "details": ve.errors()}), 400
    except json.JSONDecodeError:
        print(f"âŒ Invalid JSON: {llm_raw_output}")
        return jsonify({"error": "Invalid JSON from LLM", "raw_output": llm_raw_output}), 500
    except Exception as e:
        print(f"âŒ Server Error: {e}")
        return jsonify({"error": "Internal Server Error", "message": str(e)}), 500

if __name__ == '__main__':
    print(f"ğŸš€ Satellite Semantic Engine (powered by {MODEL_NAME}) is running on port 5000...")
    app.run(host='0.0.0.0', port=5000, debug=True)